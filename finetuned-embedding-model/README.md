---
tags:
- sentence-transformers
- sentence-similarity
- feature-extraction
- generated_from_trainer
- dataset_size:32344
- loss:SoftmaxLoss
widget:
- source_sentence: i purchased two of these and both work great. i will keep them
    in the house and use them when we go to bed. the first one was a little too big
    for my cat and it didn't fit. the second one was too small for my dog and it was
    too small for my dog. i will reorder these again. i will definitely buy another
    one.this is a very sturdy crate and is very sturdy. it is well made and does not
    slip out of the crate. the only thing i wish i could find was a "sturdy" piece
    of cardboard that would hold up. the only downside is the zip-lock makes it impossible
    to secure the crate. i would have to get it off and put it back in. i had to go
    through several pieces of cardboard, but i have no regrets. my dogs will play
    with this crate on a regular basis.i have a dog who is a rough chewer. she is
    a 5 pound dog and this is the only toy she will eat. she loves these balls and
    seems to enjoy the taste. it is hard to find them in stores, but she usually gets
    them for her when she gets home. i have tried many brands, but this is the only
    one she will eat. i will continue to purchase this product.my cats love this food!
    it's pretty healthy for them and a good value. the ingredients are good too! they
    love the taste and the price is great.great quality product! no problems at all.
    i ordered the second set of 3 and it was all the same. the dog loved them and
    didn
  sentences:
  - i purchased two of these and both work great. i will keep them in the house and
    use them when we go to bed. the first one was a little too big for my cat and
    it didn't fit. the second one was too small for my dog and it was too small for
    my dog. i will reorder these again. i will definitely buy another one.this is
    a very sturdy crate and is very sturdy. it is well made and does not slip out
    of the crate. the only thing i wish i could find was a "sturdy" piece of cardboard
    that would hold up. the only downside is the zip-lock makes it impossible to secure
    the crate. i would have to get it off and put it back in. i had to go through
    several pieces of cardboard, but i have no regrets. my dogs will play with this
    crate on a regular basis.i have a dog who is a rough chewer. she is a 5 pound
    dog and this is the only toy she will eat. she loves these balls and seems to
    enjoy the taste. it is hard to find them in stores, but she usually gets them
    for her when she gets home. i have tried many brands, but this is the only one
    she will eat. i will continue to purchase this product.my cats love this food!
    it's pretty healthy for them and a good value. the ingredients are good too! they
    love the taste and the price is great.great quality product! no problems at all.
    i ordered the second set of 3 and it was all the same. the dog loved them and
    didn
  - was supposed to be burgundy, but it's just a bit too much. the only downside is
    that it's very hard to get a good grip on the handle. the handle is made of metal
    and it's not stiff enough to hold a finger. this is a problem for most people.
    the only reason i gave it 4 stars is because it is a
  - i love vanity fair bras, and i love the look. i will keep my purse in the drawer
- source_sentence: looks like another fun one. suspending disbelief but hey that's
    what escapism in reading is for.
  sentences:
  - i purchased this for my sons graduation party. with cupcakes being "all the rage"
    now i was excited to have them professionally baked and then displayed on this
    4 tier stand. well, clearly this stand is made for miniature cupcakes. i looked
    at sooo many stands and really hoped this would have worked. we tried adjusting
    the individual holders, but no luck. sadly we were not able to use it. maybe you
    could display 12 cupcakes by placing one on every other holder. i hope the seller
    would be generous enough to allow me to return this since it was not used.
  - looks like another fun one. suspending disbelief but hey that's what escapism
    in reading is for.
  - i like the way he makes history interesting and easy to visualize. his use of
    many characters, make the stormier interesting.
- source_sentence: i just had to hide those showing wire and hide them from my sight
    and now i do not notice them at all in plain view.
  sentences:
  - i just had to hide those showing wire and hide them from my sight and now i do
    not notice them at all in plain view.
  - this review is for plantar fasciitis and these are not. these are the only ones
    i have that have the best support, and they're the ones i'm going to use for a
    couple of weeks. i have a foot problem and i have worn them for two weeks now.
    they don't feel like they will last very long, but i'm hoping they will last longer.
    i just wish i could have gotten a size up.i love these shoes. i have been wearing
    them for years, and i have never had a problem with them. i have just had a pair
    of these and am happy with them. they are not as big as i thought they would be,
    and the soles are a little short. i would say that i would order a size up if
    you are on the smaller side. the shoes are very comfortable. i wear them all the
    time. i have had them
  - box was dusty on the floor. the only reason i gave it 4 stars is because the one
    we
- source_sentence: a 9 mile hole in the ground and an even bigger hole in my wednesday
    night.
  sentences:
  - a 9 mile hole in the ground and an even bigger hole in my wednesday night.
  - i bought this for my dog (border collie mix) and she loves it. it's very comfortable
    and she can really relax. i would highly recommend this bed. it's easy to assemble
    and sturdy. i also bought a replacement cover as well.
  - the dogs love them and, if they are ever fed these, they will turn up the odor
    and chase them all over the house.
- source_sentence: my puppy girl loves these treats. the only problem is that she's
    only 2 lbs and the treats
  sentences:
  - my puppy girl loves these treats. the only problem is that she's only 2 lbs and
    the treats
  - great tap shoe but the regular was too narrow and hurt my daughter's toes. ordered
    her wide and they were much better!
  - once around is one of the most entertaining movies i've seen in a long time. it
    has a lot of heart and is definitely a must see for the whole family. the soundtrack
    is great, and it's great to see a movie that is so different and different from
    the rest of the movie. the acting is also great. i'm not sure if it's a comedy
    or a film about a kid, but i think it's an interesting story. i think the main
    characters will have a lot of fun with each other, but i think the kids will have
    a lot of fun with each other, and maybe they'll have a lot of fun with each other.
    it's a fun movie, and it's a great movie to watch over and over. it's a good movie
    to watch over and over again, and it's a good movie to watch over and over again.
    i don't know if it's a comedy or a film about a kid, but i think it's a fun movie
    to watch over and over again, and it's a good movie to watch over and over again,
    and it's a good movie to watch over and over again, and it's a good movie to watch
    over and over again. it's a good movie to watch
pipeline_tag: sentence-similarity
library_name: sentence-transformers
---

# SentenceTransformer

This is a [sentence-transformers](https://www.SBERT.net) model trained. It maps sentences & paragraphs to a 384-dimensional dense vector space and can be used for semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more.

## Model Details

### Model Description
- **Model Type:** Sentence Transformer
<!-- - **Base model:** [Unknown](https://huggingface.co/unknown) -->
- **Maximum Sequence Length:** 256 tokens
- **Output Dimensionality:** 384 dimensions
- **Similarity Function:** Cosine Similarity
<!-- - **Training Dataset:** Unknown -->
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Documentation:** [Sentence Transformers Documentation](https://sbert.net)
- **Repository:** [Sentence Transformers on GitHub](https://github.com/UKPLab/sentence-transformers)
- **Hugging Face:** [Sentence Transformers on Hugging Face](https://huggingface.co/models?library=sentence-transformers)

### Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel 
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Normalize()
)
```

## Usage

### Direct Usage (Sentence Transformers)

First install the Sentence Transformers library:

```bash
pip install -U sentence-transformers
```

Then you can load this model and run inference.
```python
from sentence_transformers import SentenceTransformer

# Download from the ðŸ¤— Hub
model = SentenceTransformer("sentence_transformers_model_id")
# Run inference
sentences = [
    "my puppy girl loves these treats. the only problem is that she's only 2 lbs and the treats",
    "my puppy girl loves these treats. the only problem is that she's only 2 lbs and the treats",
    "great tap shoe but the regular was too narrow and hurt my daughter's toes. ordered her wide and they were much better!",
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 384]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities.shape)
# [3, 3]
```

<!--
### Direct Usage (Transformers)

<details><summary>Click to see the direct usage in Transformers</summary>

</details>
-->

<!--
### Downstream Usage (Sentence Transformers)

You can finetune this model on your own dataset.

<details><summary>Click to expand</summary>

</details>
-->

<!--
### Out-of-Scope Use

*List how the model may foreseeably be misused and address what users ought not to do with the model.*
-->

<!--
## Bias, Risks and Limitations

*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*
-->

<!--
### Recommendations

*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*
-->

## Training Details

### Training Dataset

#### Unnamed Dataset

* Size: 32,344 training samples
* Columns: <code>sentence_0</code>, <code>sentence_1</code>, and <code>label</code>
* Approximate statistics based on the first 1000 samples:
  |         | sentence_0                                                                          | sentence_1                                                                          | label                                           |
  |:--------|:------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------|:------------------------------------------------|
  | type    | string                                                                              | string                                                                              | int                                             |
  | details | <ul><li>min: 12 tokens</li><li>mean: 81.28 tokens</li><li>max: 256 tokens</li></ul> | <ul><li>min: 12 tokens</li><li>mean: 81.28 tokens</li><li>max: 256 tokens</li></ul> | <ul><li>0: ~52.60%</li><li>1: ~47.40%</li></ul> |
* Samples:
  | sentence_0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | sentence_1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | label          |
  |:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------|
  | <code>best barrel squeegie/swab i've ever used in the 15 years i've been paintballing! it just takes really one try to take nearly all the paint out. these should be in every paintballer's gearbag. i bought two, but i'm utterly surprised how durable the thing is, and how insanely easy it is to clean it. now only is the squeegie portion easy to clean on the fly, the swab dries mindbogglingly quickly so all you have to do is just literally dust it off and use it again.</code> | <code>best barrel squeegie/swab i've ever used in the 15 years i've been paintballing! it just takes really one try to take nearly all the paint out. these should be in every paintballer's gearbag. i bought two, but i'm utterly surprised how durable the thing is, and how insanely easy it is to clean it. now only is the squeegie portion easy to clean on the fly, the swab dries mindbogglingly quickly so all you have to do is just literally dust it off and use it again.</code> | <code>0</code> |
  | <code>this adjustable wrench is fine for small jobs. there were some burrs on the adjustment screw and the overall finish is fairly cheap. note that this is made in china.</code>                                                                                                                                                                                                                                                                                                             | <code>this adjustable wrench is fine for small jobs. there were some burrs on the adjustment screw and the overall finish is fairly cheap. note that this is made in china.</code>                                                                                                                                                                                                                                                                                                             | <code>0</code> |
  | <code>works great. we use these at cub scout summer camp. me and my son used these and after a day, other dads were asking if i had anymore. you can reseal them in individual bags they come in, which makes them last longer. would buy again.</code>                                                                                                                                                                                                                                        | <code>works great. we use these at cub scout summer camp. me and my son used these and after a day, other dads were asking if i had anymore. you can reseal them in individual bags they come in, which makes them last longer. would buy again.</code>                                                                                                                                                                                                                                        | <code>0</code> |
* Loss: [<code>SoftmaxLoss</code>](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#softmaxloss)

### Training Hyperparameters
#### Non-Default Hyperparameters

- `per_device_train_batch_size`: 16
- `per_device_eval_batch_size`: 16
- `num_train_epochs`: 4
- `multi_dataset_batch_sampler`: round_robin

#### All Hyperparameters
<details><summary>Click to expand</summary>

- `overwrite_output_dir`: False
- `do_predict`: False
- `eval_strategy`: no
- `prediction_loss_only`: True
- `per_device_train_batch_size`: 16
- `per_device_eval_batch_size`: 16
- `per_gpu_train_batch_size`: None
- `per_gpu_eval_batch_size`: None
- `gradient_accumulation_steps`: 1
- `eval_accumulation_steps`: None
- `torch_empty_cache_steps`: None
- `learning_rate`: 5e-05
- `weight_decay`: 0.0
- `adam_beta1`: 0.9
- `adam_beta2`: 0.999
- `adam_epsilon`: 1e-08
- `max_grad_norm`: 1
- `num_train_epochs`: 4
- `max_steps`: -1
- `lr_scheduler_type`: linear
- `lr_scheduler_kwargs`: {}
- `warmup_ratio`: 0.0
- `warmup_steps`: 0
- `log_level`: passive
- `log_level_replica`: warning
- `log_on_each_node`: True
- `logging_nan_inf_filter`: True
- `save_safetensors`: True
- `save_on_each_node`: False
- `save_only_model`: False
- `restore_callback_states_from_checkpoint`: False
- `no_cuda`: False
- `use_cpu`: False
- `use_mps_device`: False
- `seed`: 42
- `data_seed`: None
- `jit_mode_eval`: False
- `use_ipex`: False
- `bf16`: False
- `fp16`: False
- `fp16_opt_level`: O1
- `half_precision_backend`: auto
- `bf16_full_eval`: False
- `fp16_full_eval`: False
- `tf32`: None
- `local_rank`: 0
- `ddp_backend`: None
- `tpu_num_cores`: None
- `tpu_metrics_debug`: False
- `debug`: []
- `dataloader_drop_last`: False
- `dataloader_num_workers`: 0
- `dataloader_prefetch_factor`: None
- `past_index`: -1
- `disable_tqdm`: False
- `remove_unused_columns`: True
- `label_names`: None
- `load_best_model_at_end`: False
- `ignore_data_skip`: False
- `fsdp`: []
- `fsdp_min_num_params`: 0
- `fsdp_config`: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
- `fsdp_transformer_layer_cls_to_wrap`: None
- `accelerator_config`: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}
- `deepspeed`: None
- `label_smoothing_factor`: 0.0
- `optim`: adamw_torch
- `optim_args`: None
- `adafactor`: False
- `group_by_length`: False
- `length_column_name`: length
- `ddp_find_unused_parameters`: None
- `ddp_bucket_cap_mb`: None
- `ddp_broadcast_buffers`: False
- `dataloader_pin_memory`: True
- `dataloader_persistent_workers`: False
- `skip_memory_metrics`: True
- `use_legacy_prediction_loop`: False
- `push_to_hub`: False
- `resume_from_checkpoint`: None
- `hub_model_id`: None
- `hub_strategy`: every_save
- `hub_private_repo`: None
- `hub_always_push`: False
- `gradient_checkpointing`: False
- `gradient_checkpointing_kwargs`: None
- `include_inputs_for_metrics`: False
- `include_for_metrics`: []
- `eval_do_concat_batches`: True
- `fp16_backend`: auto
- `push_to_hub_model_id`: None
- `push_to_hub_organization`: None
- `mp_parameters`: 
- `auto_find_batch_size`: False
- `full_determinism`: False
- `torchdynamo`: None
- `ray_scope`: last
- `ddp_timeout`: 1800
- `torch_compile`: False
- `torch_compile_backend`: None
- `torch_compile_mode`: None
- `dispatch_batches`: None
- `split_batches`: None
- `include_tokens_per_second`: False
- `include_num_input_tokens_seen`: False
- `neftune_noise_alpha`: None
- `optim_target_modules`: None
- `batch_eval_metrics`: False
- `eval_on_start`: False
- `use_liger_kernel`: False
- `eval_use_gather_object`: False
- `average_tokens_across_devices`: False
- `prompts`: None
- `batch_sampler`: batch_sampler
- `multi_dataset_batch_sampler`: round_robin

</details>

### Training Logs
| Epoch  | Step | Training Loss |
|:------:|:----:|:-------------:|
| 0.9881 | 500  | 0.5071        |
| 1.9763 | 1000 | 0.4497        |
| 2.9644 | 1500 | 0.4414        |
| 3.9526 | 2000 | 0.4364        |


### Framework Versions
- Python: 3.10.16
- Sentence Transformers: 4.1.0
- Transformers: 4.47.0
- PyTorch: 2.5.1+cu124
- Accelerate: 1.2.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citation

### BibTeX

#### Sentence Transformers and SoftmaxLoss
```bibtex
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
```

<!--
## Glossary

*Clearly define terms in order to be accessible across audiences.*
-->

<!--
## Model Card Authors

*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*
-->

<!--
## Model Card Contact

*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*
-->